# Knowledge Distillation Training Requirements
# Install with: pip install -r requirements.txt

# Core dependencies
torch>=2.1.0
transformers>=4.51.0  # Required for Qwen3 support
datasets>=2.14.0
accelerate>=0.27.0
peft>=0.10.0

# TRL for GKD and SFT
trl>=0.26.0

# DeepSpeed for distributed training
deepspeed>=0.12.0

# Configuration
pyyaml>=6.0

# Logging and monitoring
wandb>=0.16.0
tensorboard>=2.15.0

# Flash Attention (optional but recommended)
# Install manually: pip install flash-attn --no-build-isolation
# flash-attn>=2.5.0

# Utilities
tqdm>=4.66.0
numpy>=1.24.0

